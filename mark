import pandas as pd
import os

def process_excel_folder(folder_path):
    """
    Process Excel files while handling sheets with <6 columns
    """
    all_data = []

    for filename in os.listdir(folder_path):
        if filename.endswith('.xlsx'):
            file_path = os.path.join(folder_path, filename)
            
            try:
                with pd.ExcelFile(file_path) as excel:
                    first_sheet = excel.sheet_names[0]
                    
                    # Read first 6 columns dynamically
                    df = pd.read_excel(
                        excel,
                        sheet_name=first_sheet,
                        usecols=lambda x: x < 6,  # Flexible column handling
                        engine='openpyxl'
                    )
                    
                    # Check required columns exist in actual columns read
                    if {'Grade', 'Annual'}.issubset(df.columns):
                        agg_df = df.groupby('Grade', as_index=False).agg(
                            Min_rate=('Annual', 'min'),
                            Max_rate=('Annual', 'max')
                        )
                        agg_df['Category'] = filename
                        all_data.append(agg_df)
                    else:
                        print(f"Skipping {filename} - Required columns missing in first {df.shape[1]} columns")
            except Exception as e:
                print(f"Error processing {filename}: {str(e)}")
                continue

    return pd.concat(all_data, ignore_index=True)[['Grade', 'Min_rate', 'Max_rate', 'Category']]

# Usage:
# result_df = process_excel_folder("/your/folder/path")
# display(result_df)


1. **Process Excel files** in a folder  
2. For **each file**:  
   - Read **first sheet**  
   - Keep **first 6 columns**  
   - Find **min/max** of "Annual" per Grade  
   - Add **filename** as Category  
3. **Combine results** into final DataFrame  

*(Handles varying column counts safely)*
